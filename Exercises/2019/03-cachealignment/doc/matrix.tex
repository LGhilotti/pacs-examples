 %&latex
\documentclass[smaller,a4paper,allowframebreaks]{beamer}
\usepackage{amsmath,amssymb,pdfsync,listings}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{truncate}
\usepackage[final]{pdfpages}
\usepackage{times}
\usepackage{pgffor}
\usepackage[english]{babel}

\begin{document}
\title{A (Not So) Simple (Full) Matrix Class}
\frame{\titlepage}

\begin{frame}
\frametitle{Exercise}

\begin{itemize}

  
\item Implement a
      library for matrices (and cloumn vectors 
      implemented as 1-column matrices) based on 
      STL containers such as \lstinline[language=C++]{std::vector<>}
      or \lstinline[language=C++]{std::array<>}
      with the following methods/functions
      \begin{itemize}
      \item transpose : $A = A^{T}$
      \item solve : solve $A x = b$ by means of gaussian eliminition with partial pivoting by rows
      \item operator* : matrix-matrix and matrix-vector multiplication
      \end{itemize}      
\end{itemize}
\end{frame}

\begin{frame}[allowframebreaks]\frametitle{Solution}
\begin{itemize}
\item {\tt matrix-0.1/matrix.\{h,cpp\}}\\[3mm]
\begin{itemize}
\item \lstinline[language=C++]{std::array<>}
      requires the size to be known at compile time,
      in order to make the \lstinline[language=C++]{matrix}
      object configurable at run time we use 
      \lstinline[language=C++]{std::vector<>}\\[3mm]
\item matrices ar organized as \emph{column major}, {\it i.e.}
      %$A(i, j) = $ \lstinline[language=C++]{data[i + j * rows ()]}, 
      conversion from 1d to 2d indexing is performed by the utility
      (private) function \lstinline[language=C++]{sub2ind}\\[3mm]
\item access to elements is implemented both in const and non-const
      versions, by overloading \lstinline[language=C++]{operator()} \\[3mm]
\item data is private, \emph{getter methods} expose what is needed to 
      the user, both const and non-const versions are provided \\[3mm]
\item naive implementation of matrix-matrix multiplication is slow 
      because it has low \emph{data locality}
      (see below more about memory hierarchy and cache optimized algorithms), 
      simply transposing the left matrix factor improves performance significantly\\[3mm]
\item \lstinline[language=C++]{\#include <ctime>} header provides timing utilities,
      \lstinline[language=C++]{tic ()} and \lstinline[language=C++]{toc (x)} macros
      start and stop the timer (like in Matlab)
\end{itemize}

\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Exercise 2}

\begin{itemize}
\item Transpose the first factor in matrix multiplication before performing the product
\item Compare speed with previous implementation
\item {\tt matrix-0.2/matrix.\{h,cpp\}}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Exercise 3}

\begin{itemize}
\item Include the {\tt Eigen/Dense} header
\item Use the {\tt Eigen::Map} template class to wrap the matrix data and interpret it as {\tt Eigen::MatrixXd}
\item Compare speed with previous implementation
\item {\tt matrix-0.3/matrix.\{h,cpp\}}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Exercise 4}

\begin{itemize}
\item Link to Openblas
\item Use the {\tt DGEMM} function to perform the matrix-matrix product
\item {\tt matrix-0.4/matrix.\{h,cpp\}}
\end{itemize}
\end{frame}

\end{document}